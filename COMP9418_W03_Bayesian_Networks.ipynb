{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UNSW-COMP9418/Week03/blob/main/COMP9418_W03_Bayesian_Networks.ipynb)\n",
    "\n",
    "\n",
    "# Bayesian Networks\n",
    "**COMP9418 W03 Tutorial**\n",
    "\n",
    "- Instructor: Gustavo Batista\n",
    "- School of Computer Science and Engineering, UNSW Sydney\n",
    "- Notebook designed by Gustavo Batista and Jeremy Gillen from a notebook developed by Daniel Mackinlay and Edwin V. Bonilla\n",
    "- Last update 6th September 2022\n",
    "$$\n",
    "% macros\n",
    "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's tutorial, we will start exploring representation and inference with Bayesian networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "You will need certain packages installed to run this notebook.\n",
    "\n",
    "If you are using Google Colab or ``conda``'s default\n",
    "[full installation](https://conda.io/docs/install/full.html),\n",
    "these requirements should all be satisfied already.\n",
    "\n",
    "If you are using ``virtualenv`` or other native package management,\n",
    "you may need to run this command:\n",
    "\n",
    "```python\n",
    "pip3 install pandas\n",
    "```\n",
    "\n",
    "To render a visualization of some graphical models, you also need to install [Graphviz](http://www.graphviz.org/download). We have already used this library in Tutorial 1, thus, you should have it installed. If you do not have it and use the conda installation, then use the command ```conda install python-graphviz```. \n",
    "\n",
    "You will also need to download the preprocessed `icu_diag.csv` data set (see data file for this tutorial in WebCMS3) and put it in the same folder as this notebook.\n",
    "\n",
    "Once we have done all that, we import some useful modules for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# combinatorics\n",
    "from itertools import product"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAjCAYAAACHIWrsAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAmdEVYdENyZWF0aW9uIFRpbWUARnJpIDI0IFNlcCAyMDIxIDE0OjM3OjQ0aIIa6AAAAQZJREFUSIntl7ENgzAQRT9RGmozhHcwQzADrhnJHoIZjh1gCGpKUhklkTF3kROl8K8Q1vH0775tUe37vuOHuv0SVoAFWIBR3WMv53mGcw7ruiaLjTGw1oqAUYccGABM0wTnnAgYdRhg3vvTwr7vDygAttMsM5Q4zRYaLjRrSjnQ7NsizPRM0dBwFAtUCFJK/3/SEJF47z1L1FIiOlqplELXdWIg2+EzDADGcQQRfQf4Dgvy3ouhLOCyLABeUxiewxpXrBlaa2GMgdb6cNq2LZqmgdZaBGTPMPZhKUwEzCXxSZO6sj4G1nWNbdtYR9W7lFLJ9WhLh2G4LDyDXV3EVfmZKcC/Bz4AkSlmVk2fKtsAAAAASUVORK5CYII="
    },
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAfCAYAAACGVs+MAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAmdEVYdENyZWF0aW9uIFRpbWUARnJpIDI0IFNlcCAyMDIxIDE0OjM3OjMxV6l4oAAAAMxJREFUSInt1DsShCAMBuCfna1spYVWa2/DRfQOnMax9SLU0sbWlq22WsU4jsMWSUky5BseUSmlhILxKtlcAAIQwF8A3pwiIsK6rj/rxhhUVfUsgIjQ9/1uzhiDYRhuIdTZKB7HEdM0HebruobWejdnrYVzLgtgXQFw/bi3bcM8z2iaBl3X3Qc459C2LRsQQoD3HsuyZAHFf4EABFAcwP6GMUYopdgbxxhZdaeTMDeKOeG9P5yULMAXQUSXm2uts83ZgCej+CMUgAAE8AGbgkb99Z50xgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import classes from `DiscreteFactors.py` and `Graph.py` developed in previous tutorials. If you are using Colab, upload the files by clicking the \"files\" ![image.png](attachment:image.png) button on the left side of the page, then the \"upload files\" ![image-2.png](attachment:image-2.png) button. Then select the relevant python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `pandas`\n",
    "\n",
    "We will be using an external library for the loading tabular data: `pandas.DataFrame` is somewhat similar to `R`. \n",
    "If you wish to know more about that, [check out the Pandas intro](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html). We will mostly be ignoring this library, except to load data and display it in nice tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# The Data\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "These data correspond to the problem in the theory part of the tutorial for this week, i.e. the Bayesian network for medical diagnosis in an intensive care unit (ICU). The data are in `csv` format.\n",
    "We can load this in several ways in python, but the most convenient for this purpose \n",
    "is to load it as a `DataFrame` in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "!wget 'https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/icu_diag.csv'\n",
    "\n",
    "data = pd.read_csv(open('icu_diag.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data frame is an attribute-value table. It contais 1000 rows (examples), each one correponding to a patient in the intensive care unit. Each row has nine colums (attributes). Each column correponds to one variable in the Bayesian network. The next figure illustrates the network.\n",
    "\n",
    "![ICU Graph](img/ICU_graph.png \"Graph exercise\")\n",
    "\n",
    "We can use the command ``data.head()`` to display the first $n$ rows (default = 5) of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the cariables are encoded as follows:\n",
    "\n",
    "| Variable  |  Value  |  Coding |\n",
    "| :-------: | :-----: | ------: |\n",
    "| H, L, A   |  False  | 0       |\n",
    "| H, L, A   |  True   | 1       |\n",
    "| V, S, T   |  Low    | 0       |\n",
    "| V, S, T   |  High   | 1       |\n",
    "| C, O, B   |  Low    | 0       |\n",
    "| C, O, B   |  Medium | 1       |\n",
    "| C, O, B   |  High   | 2       |\n",
    "\n",
    "For now, we will keep this encoding as provided in the data file. However, replacing the numerical codes by symbolic labels may improve the results readability. To keep this notebook short, we will leave this extension as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing a Bayesian Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's first represent the graph using the Graph object discussed in the Week 1 tutorial. We created a stub for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph({\n",
    "    'L': ['S', 'V'],\n",
    "    'H': ['S', 'V'],\n",
    "    # TODO\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use GraphViz to display the graph representation, so we can assure we did not forget any edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {\n",
    "    'L': '0,3!',\n",
    "    'H': '1,3!',\n",
    "    'S': '0,2!',\n",
    "    'V': '1,2!',\n",
    "    'A': '2,2!',\n",
    "    'O': '0,1!',\n",
    "    'C': '1,1!',\n",
    "    'T': '2,1!',\n",
    "    'B': '1,0!',\n",
    "}\n",
    "graph.show(positions=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to declare a data structure with the possible outcomes for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible outcomes, by variable\n",
    "outcomeSpace = dict(\n",
    "    H=(0,1),\n",
    "    L=(0,1),\n",
    "    A=(0,1),\n",
    "    V=(0,1),\n",
    "    S=(0,1),\n",
    "    T=(0,1),\n",
    "    C=(0,1,2),\n",
    "    O=(0,1,2),\n",
    "    B=(0,1,2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine these two data structures to represent a Bayes net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet():\n",
    "    def __init__(self, graph, outcomeSpace=None, factor_dict=None):\n",
    "        self.graph = graph\n",
    "        self.outcomeSpace = dict()\n",
    "        self.factors = dict()\n",
    "        if outcomeSpace is not None:\n",
    "            self.outcomeSpace = outcomeSpace\n",
    "        if factor_dict is not None:\n",
    "            self.factors = factor_dict\n",
    "        \n",
    "model = BayesNet(graph, outcomeSpace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have also introduced a variable called `factors`. The purpose of this variable is to hold all the factors associated with the connections in this Bayes Net. We could use a list here, or a set, but since each factor represents the relationship between a child node and its parents, it is convenient to label the factors with the name of the child node. E.g. `self.factors['B']` would contain the probability distribution $P(B|O,T)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the probability tables from the data\n",
    "\n",
    "We need to estimate a discrete distribution\n",
    "for each (conditional) probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate parameters by constructing conditional distributions for each node in our graph.\n",
    "We will take the proportions of empirical counts as estimates of the probabilities of the counted outcomes, i.e.\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x},\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x}\\mid\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N_\\boldsymbol{y}},\n",
    "$$\n",
    "\n",
    "where $N_{\\boldsymbol{x}, \\boldsymbol{y}}$ is the number of observations of that outcome,\n",
    "$$N_{\\boldsymbol{x}, \\boldsymbol{y}}:=\\sum_i\\boldsymbol{X_i}=\\boldsymbol{x}\\cap\\boldsymbol{Y_i}=\\boldsymbol{y},$$ and $N$ is the total number of observations.\n",
    "\n",
    "Later, we will see this procedure of estimating parameters corresponds to the Maximum Likelihood Estimate (MLE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another helper function. This will calculate joint occurrence probability tables.\n",
    "you invoke it like this\n",
    "```\n",
    "factor = estimateFactor(data, 'V', ['H', 'L'])\n",
    "```\n",
    "to estimate all conditional occurrence probabilities of $V|H,L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [True, False, False]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estimateFactor(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `outcomeSpace`, a dict that maps variable names to a tuple of possible outcomes\n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    f = Factor(list(parent_names)+[var_name], outcomeSpace)\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            f[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum()\n",
    "            \n",
    "    return f\n",
    "\n",
    "\n",
    "##############################\n",
    "# Test code\n",
    "##############################\n",
    "print(estimateFactor(data, 'V', ['H', 'L'], outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the above function to calculate the probability tables for all 9 variables of the ICU Bayesian Network. \n",
    "\n",
    "However, notice that the `estimateFactor(data, var_name, parent_names, outcomeSpace)` requires the variable name (`var_name`) and the parent names (`parent_names`). We do not have this information readly available. The adjacency list provides the children of each node, not its parents.\n",
    "\n",
    "The question is, how can we invert the graph data structure so that each node will point to its parents? Yes, the answer is the graph transpose operation, implemented in Week 1 tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphT = graph.transpose()\n",
    "graphT.show(positions=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a method on the class BayesNet to learn each conditional factor. Since a Bayesian network contains factors over each variable, conditional on its parents, it's convienient to store each factor in a dictionary. The dictionary will associate each child variable name with a conditional factor: $\\phi(child | parents)$.\n",
    "\n",
    "Use the `estimateFactor(data, var_name, parent_names, outcomeSpace)` function to calculate probability tables for all 9 variables in our DAG (Bayesian network structure in the theory part of the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet(BayesNet):\n",
    "    def learnParameters(self, data):\n",
    "        '''\n",
    "        Iterate over each node in the graph, and use the given data\n",
    "        to estimate the factor P(node|parents), then add the new factor \n",
    "        to the `self.factors` dictionary.\n",
    "        '''\n",
    "        graphT = self.graph.transpose()\n",
    "        for node, parents in graphT.adj_list.items():\n",
    "            # TODO estimate each factor and add it to the `self.factors` dictionary\n",
    "            ...\n",
    "            \n",
    "##############################\n",
    "# Test code\n",
    "##############################            \n",
    "model = BayesNet(graph, outcomeSpace)\n",
    "model.learnParameters(data)\n",
    "print('estimated P(H)=')\n",
    "print(model.factors['H'])\n",
    "print('estimated P(V|H,L)=')\n",
    "print(model.factors['V'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented this code correctly, you should see an output like this:\n",
    "    \n",
    "```\n",
    "estimated P(H)=\n",
    "╒═════╤═══════╕\n",
    "│   H │    Pr │\n",
    "╞═════╪═══════╡\n",
    "│   0 │ 0.801 │\n",
    "├─────┼───────┤\n",
    "│   1 │ 0.199 │\n",
    "╘═════╧═══════╛\n",
    "\n",
    "estimated P(V|H,L)=\n",
    "╒═════╤═════╤═════╤═══════════╕\n",
    "│   L │   H │   V │        Pr │\n",
    "╞═════╪═════╪═════╪═══════════╡\n",
    "│   0 │   0 │   0 │ 0.0447958 │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   0 │   0 │   1 │ 0.955204  │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   0 │   1 │   0 │ 0.994764  │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   0 │   1 │   1 │ 0.0052356 │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   1 │   0 │   0 │ 0         │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   1 │   0 │   1 │ 1         │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   1 │   1 │   0 │ 1         │\n",
    "├─────┼─────┼─────┼───────────┤\n",
    "│   1 │   1 │   1 │ 0         │\n",
    "╘═════╧═════╧═════╧═══════════╛\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probabilities by naïve summation\n",
    "\n",
    "We are interested in calculating the conditional distributions.\n",
    "For the moment we will attempt to find the conditional distribution\n",
    "$p(L\\mid C=\\text{high})$.\n",
    "\n",
    "We will compute $p(L\\mid C=\\text{high})$ by naïve summation.\n",
    "\n",
    "To do this, we will need to reconstruct each of the joint probabilities from our graph.\n",
    "Remember that we know that we know a factorization for the joint probabilities,\n",
    "specifically,\n",
    "\n",
    "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
    "\n",
    "To calculate this, we will need the factor multiplication operation we implemented in the previous tutorial (Week 2). We called this operation a `factor join`. Recall how we use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1 = model.factors['H']\n",
    "factor2 = model.factors['V']\n",
    "print(\"join p(V|H,L) and p(H):\")\n",
    "print(factor1.join(factor2))\n",
    "\n",
    "# Equivalently, we can do:\n",
    "# print(factor1*factor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now, implement a function that calculates the full joint probability of the Bayesian network model by multiplying all conditional distributions estimated from data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet(BayesNet):\n",
    "    def joint(self):\n",
    "        '''\n",
    "        Join every factor in the network, and return the resulting factor.\n",
    "        '''\n",
    "        factor_list = list(self.factors.values())\n",
    "        \n",
    "        accumulator = factor_list[0]\n",
    "        ... # TODO join every factor in the list (requires loop)\n",
    "        \n",
    "        return accumulator\n",
    "    \n",
    "#########################\n",
    "# Test code\n",
    "#########################\n",
    "model = BayesNet(graph, outcomeSpace)\n",
    "model.learnParameters(data)\n",
    "p = model.joint()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct implementation should provide the following output. The columns may be in a different order, depending on the order that the factors were joined. At least you can compare the first row.\n",
    "\n",
    "Notice the size of this table as well as some very small probability values. We can realize how difficult it is to elicit such a probability table from a domain expert. It is much easier to work with smaller conditional tables.\n",
    "\n",
    "```\n",
    "╒═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════════════╕\n",
    "│   L │   H │   S │   V │   O │   A │   T │   C │   B │          Pr │\n",
    "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════════════╡\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │ 0.000363366 │\n",
    "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │ 0           │\n",
    "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   2 │ 0           │\n",
    "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │   0 │ 1.66682e-05 │\n",
    "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │   1 │ 0           │\n",
    "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │   2 │ 0           │\n",
    "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
    "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   2 │   0 │ 6.66726e-06 │\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering Probabilistic Queries\n",
    "\n",
    "Given the joint distribution, we can answer any probabilistic queries we like. For instance, the query we posed before, $p(L\\mid C=\\text{high})$.\n",
    "\n",
    "We will need to eliminate variables through marginalization as well as observing evidence and renormalizing. We have implemented three functions to perform these tasks in Week 2 tutorial.\n",
    "\n",
    "See [this](https://stackoverflow.com/a/36908) stackoverflow answer for the various uses of ** and * for packing and unpacking arguments, as used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of how to use evidence, marginalize, normalize\n",
    "\n",
    "# Create an empty factor ()\n",
    "f = Factor(['A','B','C'], {'A':[0,1], 'B':[0,1,2], 'C':[0,1]})\n",
    "\n",
    "# How to set evidence\n",
    "evidence_dict = {'A':1, 'B':2}\n",
    "f_with_evidence = f.evidence(**evidence_dict) \n",
    "\n",
    "# How to marginalize\n",
    "f_without_c = f.marginalize('C')\n",
    "\n",
    "# How to join 'f' and 'f_without_c'\n",
    "f_joined = f.join(f_without_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Implement a method `query` that receives as arguments a list of variables and a list of evidence and returns $P(variables|evidence)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet(BayesNet):\n",
    "    def query(self, q_vars, **q_evi):\n",
    "        \"\"\"\n",
    "        arguments \n",
    "        `q_vars`, list of variables in query head\n",
    "        `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "\n",
    "        Returns a new NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
    "        \"\"\"     \n",
    "\n",
    "        # first we calculate the joint distribution\n",
    "        f = self.joint()\n",
    "        \n",
    "        # Next, we set the evidence \n",
    "        f = ... # TODO\n",
    "\n",
    "        # Second, we eliminate hidden variables NOT in the query\n",
    "        ... # TODO\n",
    "        \n",
    "        # Finally, we normalize, then return the factor\n",
    "        return ... # TODO\n",
    "\n",
    "#########################\n",
    "# Test code\n",
    "#########################\n",
    "model = BayesNet(graph, outcomeSpace)\n",
    "model.learnParameters(data)\n",
    "         \n",
    "print(model.query('L', C=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct then you should see the following output:\n",
    "\n",
    "```\n",
    "╒═════╤═══════════╕\n",
    "│   L │        Pr │\n",
    "╞═════╪═══════════╡\n",
    "│   0 │ 0.947912  │\n",
    "├─────┼───────────┤\n",
    "│   1 │ 0.0520882 │\n",
    "╘═════╧═══════════╛\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional independence\n",
    "\n",
    "In this part, we will numerically estimate conditional independences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Show or refute  the conditional independences in the theory tutorial numerically. i.e. \n",
    "determine whether\n",
    "\n",
    "1. $H \\indep L$\n",
    "2. $H \\indep A$\n",
    "3. $C \\indep L$\n",
    "\n",
    "We can do this by examining the conditional versus marginal probabilities, e.g. \n",
    "\n",
    "$$H \\indep L\\Rightarrow p(H,L)=p(H)p(L)$$\n",
    "\n",
    "Or,\n",
    "\n",
    "$$H \\indep L \\Rightarrow p(H|L)=p(H).$$\n",
    "\n",
    "It is your turn, we will leave three blank cells for you to develop your code. Use the functions we have implemented in the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesNet(graph, outcomeSpace)\n",
    "model.learnParameters(data)\n",
    "\n",
    "... # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Task\n",
    "Create a python file called `BayesNet.py`, and copy the BayesNet class into this file (and the helper functions, and import statements). You will need this file for future tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
